{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import argus\n",
    "from argus import Model\n",
    "from argus.callbacks import MonitorCheckpoint, EarlyStopping, LoggingToFile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.dataset import SaltDataset\n",
    "from src.transforms import SimpleDepthTransform, DepthTransform, SaltTransform\n",
    "from src.argus_models import SaltProbModel, SaltMetaModel\n",
    "from src import config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (128, 128)\n",
    "val_folds = [0]\n",
    "train_folds = [1, 2, 3, 4]\n",
    "train_batch_size = 64\n",
    "val_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_trns = SimpleDepthTransform()\n",
    "train_trns = SaltTransform(image_size, True, 'pad')\n",
    "val_trns = SaltTransform(image_size, False, 'pad')\n",
    "train_dataset = SaltDataset(config.TRAIN_FOLDS_PATH, train_folds, train_trns, depth_trns)\n",
    "val_dataset = SaltDataset(config.TRAIN_FOLDS_PATH, val_folds, val_trns, depth_trns)\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a list of images in a row# Draw  \n",
    "def draw(imgs):\n",
    "    n = len(imgs)  # Number of images in a row\n",
    "    plt.figure(figsize=(7,n*7))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(imgs[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_to_draw = 3\n",
    "\n",
    "for img, trg in train_loader:\n",
    "    for i in range(n_images_to_draw):\n",
    "        img_i = img[i, 0, :, :].numpy()\n",
    "        cumsum_i = img[i, 1, :, :].numpy()\n",
    "        trg_i = trg[i, 0, :, :].numpy()\n",
    "        draw([img_i, cumsum_i, trg_i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'nn_module': ('DPNProbUnet', {\n",
    "        'num_classes': 1,\n",
    "        'num_channels': 3,\n",
    "        'encoder_name': 'dpn92',\n",
    "        'dropout': 0\n",
    "    }),\n",
    "    'loss': ('FbBceProbLoss', {\n",
    "        'fb_weight': 0.95,\n",
    "        'fb_beta': 2,\n",
    "        'bce_weight': 0.9,\n",
    "        'prob_weight': 0.85\n",
    "    }),\n",
    "    'prediction_transform': ('ProbOutputTransform', {\n",
    "        'segm_thresh': 0.5,\n",
    "        'prob_thresh': 0.5\n",
    "    }),\n",
    "    'optimizer': ('Adam', {'lr': 0.0001}),\n",
    "    'device': 'cuda'\n",
    "}\n",
    "\n",
    "model = SaltMetaModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    MonitorCheckpoint('/workdir/data/experiments/test_022', monitor='val_crop_iout', max_saves=3),\n",
    "    EarlyStopping(monitor='val_crop_iout', patience=50),\n",
    "    LoggingToFile('/workdir/data/experiments/test_022/log.txt')\n",
    "]\n",
    "\n",
    "model.fit(train_loader, \n",
    "          val_loader=val_loader,\n",
    "          max_epochs=1000,\n",
    "          callbacks=callbacks,\n",
    "          metrics=['crop_iout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from argus import load_model\n",
    "\n",
    "experiment_name = 'test_025'\n",
    "lr_steps = [\n",
    "    (300, 0.0001),\n",
    "    (300, 0.00003),\n",
    "    (300, 0.00001),\n",
    "    (300, 0.000003),\n",
    "    (1000, 0.0000001)\n",
    "]\n",
    "\n",
    "for i, (epochs, lr) in enumerate(lr_steps):\n",
    "    print(i, epochs, lr)\n",
    "    if not i:\n",
    "        model = SaltMetaModel(params)\n",
    "    else:\n",
    "        model = load_model(f'/workdir/data/experiments/{experiment_name}/model-last.pth')\n",
    "        \n",
    "    callbacks = [\n",
    "        MonitorCheckpoint(f'/workdir/data/experiments/{experiment_name}', monitor='val_crop_iout', max_saves=2),\n",
    "        EarlyStopping(monitor='val_crop_iout', patience=50),\n",
    "        LoggingToFile(f'/workdir/data/experiments/{experiment_name}/log.txt')\n",
    "    ]    \n",
    "    \n",
    "    model.set_lr(lr)\n",
    "    model.fit(train_loader, \n",
    "          val_loader=val_loader,\n",
    "          max_epochs=epochs,\n",
    "          callbacks=callbacks,\n",
    "          metrics=['crop_iout'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
